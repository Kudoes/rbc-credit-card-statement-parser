{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0f8ef8d-e16c-4eec-9fcd-4efd2afbf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc8fe7-cba6-413b-b110-4c29ee6afe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have JAVA installed\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc228ec-1492-4d5d-81a9-e4d04029aed4",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c575198-d607-42e8-8d1f-94a2c67b2928",
   "metadata": {},
   "source": [
    "This script will complete two main functionalities:\n",
    "\n",
    "1. Extract all transactions from a directory containing RBC Visa statements (as PDF files) into a CSV file.\n",
    "2. Assign all transactions categories based on the classifications specified in the `transaction_classification.json` JSON file.\n",
    "\n",
    "**Requirements: File Naming Convention:**\n",
    "\n",
    "1. Each PDF file **must** end with a **hyphen** followed by the **year-month-day** of the statement in format `YYYY-MM-DD`. For example, a September 2022 statement filename must end in the following format: \"... -2022-09\".\n",
    "2. You must specify the source and destination directory in the code chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04b48242-5c4b-4f63-bfb1-e01018b7ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = r'./statements' # statements location\n",
    "RESULTS_DIR = r'./results' # output file location\n",
    "CATEGORY_FILE = r'transaction_classification.json' # category classification file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee079302-ff53-49ea-b454-6876f8f62e2c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c97ed86b-5900-419a-9ed4-301959fe6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean up the format of the price entries\n",
    "def parse_price(price):\n",
    "    # Define a factor variable to multiply the price with (for debit/credit)\n",
    "    factor = 1\n",
    "    \n",
    "    # Remove all commas in the price string\n",
    "    price = price.replace(\",\", \"\")\n",
    "    \n",
    "    # If the price has a negative sign, it is a payment\n",
    "    if price[0] == '-':\n",
    "        factor = -1\n",
    "        price = price[1:]\n",
    "        \n",
    "    # Convert the string to a float and multiply by appropriate factor\n",
    "    return float(price[1:]) * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322b805-f46c-41b1-88b9-aeb7662dfcd6",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "23fc3292-b0bf-4f79-bac6-a1a84babe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid months as they appear in the RBC statements\n",
    "valid_months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',\n",
    "                'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
    "\n",
    "# Create a master dataframe to store all extracted transactions from all statements\n",
    "master_df = pd.DataFrame(columns = ['Transaction Date', 'Posting Date', 'Activity', 'Amount (CAD)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97c6e9bc-fb56-4784-8e37-68c3a06ca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each statement PDF\n",
    "res = pd.DataFrame()\n",
    "for entry in os.scandir(SOURCE_DIR):\n",
    "    \n",
    "    # Ensure that the file is a PDF\n",
    "    if entry.name[-4:] == '.pdf':\n",
    "    \n",
    "        # Parse statement based on identified area markers\n",
    "        # If the statement layout changes, this will likely break and need to be updated\n",
    "        pdf_path = entry\n",
    "        dfs = tabula.read_pdf(pdf_path, \n",
    "                              stream=True,\n",
    "                              pages='all', \n",
    "                              pandas_options={'header': None}, \n",
    "                              area=(195, 57, 800, 353),\n",
    "                              columns = [58, 95.8, 128, 301]) # Columns is very important!\n",
    "\n",
    "        # Create a dataframe to store all transactions from all pages for this PDF\n",
    "\n",
    "        # Combine transactions from all pages (if > 1 page) and clean column names\n",
    "        df_transactions = pd.concat(dfs)\n",
    "        df_transactions = df_transactions.drop(df_transactions.columns[0], axis='columns').dropna()\n",
    "        df_transactions.index = np.arange(0, len(df_transactions))\n",
    "        df_transactions.columns = ['Transaction Date', 'Posting Date', 'Activity', 'Amount (CAD)']\n",
    "        \n",
    "        # Drop all rows that don't include transactions\n",
    "        df_transactions = df_transactions.loc[df_transactions['Transaction Date'].str.startswith(tuple(valid_months))]\n",
    "        \n",
    "        # Clean up the transaction amount column values\n",
    "        df_transactions['Amount (CAD)'] = df_transactions['Amount (CAD)'].apply(lambda x: parse_price(x))\n",
    "        \n",
    "        # Assign the year to the date\n",
    "        # This involves custom logic for Dec/Jan statements with transactions that span multiple years\n",
    "        statement_year_month = entry.name[-14:-7]\n",
    "        statement_year = statement_year_month.split('-')[0]\n",
    "        statement_month = statement_year_month.split('-')[1]\n",
    "        \n",
    "        # If the month is not Dec/Jan, assign simple year to transaction\n",
    "        if statement_month not in ['01', '12']:\n",
    "            df_transactions['Transaction Date'] = df_transactions['Transaction Date'] + \" \" + statement_year\n",
    "            df_transactions['Posting Date'] = df_transactions['Posting Date'] + \" \" + statement_year\n",
    "        \n",
    "        # If the statement is for January and contains (STATEMENT_YEAR - 1) transactions for December, we need to specify those\n",
    "        elif statement_month in ['01']:\n",
    "            df_transactions['Transaction Date'] = df_transactions.apply(lambda x: x['Transaction Date'] + \" {}\".format(int(statement_year)-1) \\\n",
    "                                                                        if x['Transaction Date'][:3] == \"DEC\" \\\n",
    "                                                                        else x['Transaction Date'] + \" {}\".format(int(statement_year)), axis='columns')\n",
    "            \n",
    "            df_transactions['Posting Date'] = df_transactions.apply(lambda x: x['Posting Date'] + \" {}\".format(int(statement_year)-1) \\\n",
    "                                                                        if x['Posting Date'][:3] == \"DEC\" \\\n",
    "                                                                        else x['Posting Date'] + \" {}\".format(int(statement_year)), axis='columns')\n",
    "            \n",
    "        # If the statement is for December and contains (STATEMENT_YEAR + 1) transactions for January, we need to specify those\n",
    "        # This should not be the case with the current statement format from RBC, but just to catch edge cases we include this here\n",
    "        elif statement_month in ['12']:\n",
    "            df_transactions['Transaction Date'] = df_transactions.apply(lambda x: x['Transaction Date'] + \" {}\".format(int(statement_year)+1) \\\n",
    "                                                                        if x['Transaction Date'][:3] == \"JAN\" \\\n",
    "                                                                        else x['Transaction Date'] + \" {}\".format(int(statement_year)), axis='columns')\n",
    "            \n",
    "            df_transactions['Posting Date'] = df_transactions.apply(lambda x: x['Posting Date'] + \" {}\".format(int(statement_year)+1) \\\n",
    "                                                                    if x['Posting Date'][:3] == \"JAN\" \\\n",
    "                                                                    else x['Posting Date'] + \" {}\".format(int(statement_year)), axis='columns')\n",
    "        \n",
    "        # Convert all time columns to DATETIME format\n",
    "        df_transactions['Transaction Date'] = pd.to_datetime(df_transactions['Transaction Date'],format='%b %d %Y').dt.date\n",
    "        df_transactions['Posting Date'] = pd.to_datetime(df_transactions['Posting Date'],format='%b %d %Y').dt.date\n",
    "        \n",
    "        # Append the transactions to the master dataframe\n",
    "        master_df = master_df.append(df_transactions)\n",
    "    \n",
    "# Sort the final dataframe by transaction dates\n",
    "master_df = master_df.sort_values('Transaction Date')\n",
    "\n",
    "# Re-index the rows\n",
    "master_df.index = np.arange(0, len(master_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb679e3-99e8-4a85-840b-e5c10d25c6e2",
   "metadata": {},
   "source": [
    "## Assigning Categories\n",
    "\n",
    "Now we utilize the categories defined in the `transaction_classification.json` file to assign each activity a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1ae64791-76d1-48ed-bba2-b6ad92cf8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in JSON file\n",
    "categories_file = CATEGORY_FILE\n",
    "if CATEGORY_FILE != \"\":\n",
    "    with open(categories_file) as json_file: \n",
    "        categories = json.load(json_file)\n",
    "\n",
    "    # Create new column for category\n",
    "    master_df['Category'] = None\n",
    "\n",
    "    # Iterate through categories and assign the transaction the category based on regex matching\n",
    "    for category in categories:\n",
    "        for value in categories[category]:\n",
    "            master_df.loc[master_df['Activity'].str.contains(value, regex=False), 'Category'] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1f15d-1da8-4440-96a0-30877889cb39",
   "metadata": {},
   "source": [
    "## Write Results to CSV File\n",
    "\n",
    "Now we export the parsed transactions as a CSV file.\n",
    "\n",
    "Naming format: `statements_parsed_{min_txn_date}_{max_txn_date}.csv`\n",
    "\n",
    "The `min_txn_date` is the minimum transaction date parsed from the statements. The `max_txn_date` is the maximum transaction date parsed from the statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6d61b3ce-ce52-448a-a371-d7d196da1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_txn_date = master_df['Transaction Date'].min().strftime('%Y%m%d')\n",
    "max_txn_date = master_df['Transaction Date'].max().strftime('%Y%m%d')\n",
    "\n",
    "# Write to CSV\n",
    "master_df.to_csv('{}/statements_parsed_{}_{}.csv'.format(RESULTS_DIR, min_txn_date, max_txn_date), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09657a9c-ddef-4a6c-8fa0-06e49102b40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
